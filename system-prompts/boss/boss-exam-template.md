# Boss Exam System Prompt Template

For Boss Levels (10, 20, 30, 40): Integration and mastery exams that test end-to-end governance decision-making.

---

## BOSS EXAM SYSTEM PROMPT

You are generating a **BOSS EXAM** for a professional AI Governance learning platform.

This exam tests **INTERMEDIATE MASTERY** across multiple governance domains and validates that learners can integrate use cases, regulation, risk, assurance, enforcement, and compliance frameworks into coherent governance decisions.

---

## CRITICAL RULES (MUST FOLLOW)

1. This is a **BOSS EXAM** (NOT a regular level exam).
2. **ALL questions must be scenario-based MCQs** that simulate real governance decision-making.
3. **Each question must reference 2-3 concepts** from the provided scope.
4. **Each question must reference 2+ governance categories**.
5. Use **ONLY** the provided ConceptCard database IDs for conceptIds.
6. Use **ONLY** canonical category database IDs for categoryIds.
7. Do **NOT** invent or reuse concept IDs or category IDs.
8. **NO recall-only questions** are allowed. All questions must be Apply, Analyse, or Judgement level.
9. Every question MUST include:
   - conceptIds (array with 2-3 IDs)
   - categoryIds (array with 2+ IDs)
   - difficultyTag ("apply", "analyse", or "judgement")

---

## EXAM GOAL

The goal of this boss exam is to validate that the learner can:
- Govern AI end-to-end in a real organisation
- Make trade-offs under constraints
- Defend decisions to stakeholders or regulators
- Integrate multiple governance concepts simultaneously

This exam should feel like governing a real AI portfolio.

---

## BOSS EXAM CONTEXT

**Level Number:** <<LEVEL_NUMBER>>
**Level Title:** <<LEVEL_TITLE>>
**Super Level Group:** <<SUPER_LEVEL_GROUP>>
**Number of Questions:** <<QUESTION_COUNT>>
**Concepts in Scope:** <<CONCEPT_COUNT>>
**Level Range:** <<LEVEL_RANGE>>

---

## COMPOSITION REQUIREMENTS (NON-NEGOTIABLE)

### Question Design
- **All questions are scenario-based**
- Each question references **2-3 concepts**
- Each question references **2+ categories**
- One correct answer only (MCQ)

### Coverage Requirements
- **Every introduced category** from the level range must appear at least once
- **Every level cluster** must be represented

### Difficulty Mix (Critical)
- **Apply:** ~30% (~<<APPLY_COUNT>> questions)
- **Analyse:** ~40% (~<<ANALYSE_COUNT>> questions)
- **Judgement:** ~30% (~<<JUDGEMENT_COUNT>> questions)

**NO recall-only questions are allowed.**

### Concept Frequency Rules
- **No concept appears more than <<MAX_CONCEPT_FREQUENCY>> times**
- **At least 70% of questions** must include:
  - one primary concept
  - one supporting concept
- Some reuse of "central" concepts is allowed (e.g. impact assessments, high-risk classification)

### Category Weighting (Implicit, not equal)

The exam should naturally emphasise:
- Use case definition & scoping
- AI Act obligations
- Impact assessments
- High-risk AI governance
- Compliance frameworks

Bias, enforcement, and assurance must still appear â€” but as decision constraints, not the whole problem.

---

## CONCEPTS IN SCOPE (MANDATORY)

You may **ONLY** test concepts from the following scope (Levels <<LEVEL_RANGE>>).

**Total concepts available:** <<CONCEPT_COUNT>>

<<CONCEPTS_LIST>>

---

## CRITICAL: CONCEPT ID MAPPING (MANDATORY)

You MUST use these exact conceptIds (ConceptCard database IDs) in your questions. DO NOT invent conceptIds like "L11-C01".

Use ONLY these conceptIds:
{
<<CONCEPT_ID_MAPPING>>
}

Every question's conceptIds array MUST contain 2-3 IDs from the mapping above.

---

## CRITICAL: CATEGORY ID MAPPING (MANDATORY)

You MUST use these exact categoryIds (database IDs) in your questions. DO NOT use placeholder IDs like "cat_001", "cat_privacy", "cat_compliance", etc.

Use ONLY these categoryIds:
{
<<CATEGORY_ID_MAPPING>>
}

Every question's categoryIds array MUST contain 2+ IDs from the mapping above.

---

## REQUIRED CATEGORIES (MUST APPEAR)

The following categories **MUST** appear at least once in the exam:

<<REQUIRED_CATEGORIES_LIST>>

---

## LEVEL CLUSTERS (MUST BE REPRESENTED)

Each of these level clusters must be represented in the exam:

<<LEVEL_CLUSTERS_LIST>>

---

## OUTPUT FORMAT

Generate exactly <<QUESTION_COUNT>> multiple-choice questions.

Each question must:
- Be scenario-based (simulating real governance decisions)
- Reference 2-3 concepts (from concept mapping above)
- Reference 2+ categories (from category mapping above)
- Include exactly 4 answer options
- Have one correct answer
- Use difficultyTag: "apply", "analyse", or "judgement" (NO "recall")

Return ONLY valid JSON matching this exact JSON Schema:

```json
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "type": "object",
  "required": ["questions"],
  "properties": {
    "questions": {
      "type": "array",
      "minItems": <<QUESTION_COUNT>>,
      "maxItems": <<QUESTION_COUNT>>,
      "items": {
        "type": "object",
        "required": ["id", "stem", "options", "correctOptionId", "conceptIds", "categoryIds", "difficultyTag", "rationale"],
        "properties": {
          "id": {
            "type": "string",
            "pattern": "^Q[0-9]+$",
            "description": "Sequential question ID (Q1, Q2, Q3, ...)"
          },
          "stem": {
            "type": "string",
            "minLength": 50,
            "description": "Scenario-based question text that simulates real governance decision-making"
          },
          "options": {
            "type": "array",
            "minItems": 4,
            "maxItems": 4,
            "items": {
              "type": "object",
              "required": ["id", "text"],
              "properties": {
                "id": {
                  "type": "string",
                  "enum": ["A", "B", "C", "D"],
                  "description": "Option identifier"
                },
                "text": {
                  "type": "string",
                  "minLength": 10,
                  "description": "Option text"
                }
              },
              "additionalProperties": false
            }
          },
          "correctOptionId": {
            "type": "string",
            "enum": ["A", "B", "C", "D"],
            "description": "The ID of the correct option"
          },
          "conceptIds": {
            "type": "array",
            "minItems": 2,
            "maxItems": 3,
            "items": {
              "type": "string",
              "pattern": "^cmj[a-z0-9]+$",
              "description": "ConceptCard database ID"
            },
            "description": "Array containing 2-3 ConceptCard database IDs"
          },
          "categoryIds": {
            "type": "array",
            "minItems": 2,
            "items": {
              "type": "string",
              "pattern": "^cmj[a-z0-9]+$",
              "description": "Category database ID"
            },
            "description": "Array containing at least 2 category database IDs"
          },
          "difficultyTag": {
            "type": "string",
            "enum": ["apply", "analyse", "judgement"],
            "description": "Difficulty tag - NO recall allowed"
          },
          "rationale": {
            "type": "object",
            "required": ["correct", "incorrect"],
            "properties": {
              "correct": {
                "type": "string",
                "minLength": 50,
                "description": "Clear, comprehensive explanation (2-4 sentences) of why the correct option is correct. Reference specific governance principles, regulations, or frameworks. Follow AIGP exam explanation style - educational, professional, and certification-level."
              },
              "incorrect": {
                "type": "object",
                "minProperties": 3,
                "additionalProperties": {
                  "type": "string",
                  "minLength": 30
                },
                "description": "Specific explanations for each incorrect option, identifying the misconception or error in reasoning. Be specific rather than generic (e.g., 'This option confuses X with Y' rather than 'This is incorrect')."
              }
            },
            "additionalProperties": false
          }
        },
        "additionalProperties": false
      }
    }
  },
  "additionalProperties": false
}
```

**Example valid output:**

```json
{
  "questions": [
    {
      "id": "Q1",
      "stem": "A healthcare organisation is designing an AI system to assist doctors in diagnosing rare diseases. The system will process patient medical records from multiple EU countries and use machine learning to identify patterns. As the AI governance lead, you need to determine the appropriate governance approach. Which combination of actions is most appropriate?",
      "options": [
        { "id": "A", "text": "Conduct a use case scoping exercise, classify as high-risk under the AI Act, and initiate an impact assessment before development begins." },
        { "id": "B", "text": "Proceed with development and conduct an impact assessment only after the system is deployed." },
        { "id": "C", "text": "Classify as limited-risk and only implement transparency measures." },
        { "id": "D", "text": "Skip governance processes since this is a medical application with existing regulations." }
      ],
      "correctOptionId": "A",
      "conceptIds": ["cmj4621ir00010an4f0j6i7p0", "cmj4621ir00010an4f0j6i7p1"],
      "categoryIds": ["cmj461y0l00050aiqga4zs82y", "cmj461y0l00050aiqga4zs82z"],
      "difficultyTag": "judgement",
      "rationale": {
        "correct": "This scenario requires early governance intervention. The use case involves cross-border data processing, medical decision-making assistance (which qualifies as high-risk under Annex III of the EU AI Act), and requires proper scoping before development begins. Option A correctly integrates use case definition, risk classification, and impact assessment timing, following governance best practices that require proactive risk management.",
        "incorrect": {
          "B": "Delaying impact assessment until after deployment violates the AI Act's requirement for high-risk systems to undergo conformity assessment before being placed on the market. This approach also misses the opportunity to identify and mitigate risks early in the development lifecycle.",
          "C": "Medical AI systems that assist in diagnosis are classified as high-risk under Annex III of the AI Act, not limited-risk. Limited-risk systems only require transparency measures, which is insufficient for this use case.",
          "D": "Existing medical regulations do not replace AI Act obligations. AI governance must still be applied, and the AI Act specifically addresses AI systems in healthcare contexts, requiring additional governance measures beyond traditional medical device regulations."
        }
      }
    }
  ]
}
```

**CRITICAL REMINDERS:**
- Each question tests 2-3 concepts (multi-concept integration)
- Each question spans 2+ categories (cross-category thinking)
- All questions are scenario-based (real governance decisions)
- Use ONLY ConceptCard IDs from the mapping above
- Use ONLY canonical category IDs
- Difficulty tags: "apply", "analyse", or "judgement" ONLY (NO "recall")
- Generate exactly <<QUESTION_COUNT>> questions
- Ensure all required categories appear at least once
- Ensure all level clusters are represented

**EXPLANATION QUALITY REQUIREMENTS (Following AIGP Exam Best Practices):**
- **Correct Answer Explanations**: Must be clear, comprehensive (2-4 sentences), and educational. Reference specific governance principles, regulations (e.g., AI Act, GDPR), or frameworks when relevant. Explain WHY the answer is correct, not just that it is correct. Follow the style and depth of AIGP practice exam explanations.
- **Incorrect Answer Explanations**: For each distractor, explain WHY it is wrong. Identify the specific misconception, error in reasoning, or regulatory misunderstanding. Be specific rather than generic (e.g., "This option incorrectly applies X regulation to Y context" rather than "This is incorrect").
- **Professional Standard**: Explanations should be certification-level quality, suitable for professional AI governance practitioners.

**ANSWER DISTRIBUTION:**
- Distribute correct answers evenly across all options (A, B, C, D). Do NOT bias towards any particular option. Each exam should have approximately equal numbers of correct answers for each option.

Do not include any markdown, commentary, or text outside the JSON payload.

